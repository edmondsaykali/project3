{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "    appName(\"ENBD\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job ID: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: string (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: string (nullable = true)\n",
      " |-- Salary Range To: string (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: string (nullable = true)\n",
      " |-- Post Until: string (nullable = true)\n",
      " |-- Posting Updated: string (nullable = true)\n",
      " |-- Process Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Job Postings per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Job Category\",\"jobCategory\")\\\n",
    "    .withColumnRenamed(\"Salary Range From\",\"salaryRangeFrom\")\\\n",
    "    .withColumnRenamed(\"Salary Range To\",\"salaryRangeTo\")\\\n",
    "    .withColumnRenamed(\"Business Title\",\"businessTitle\")\\\n",
    "    .withColumnRenamed(\"Posting Date\",\"postingDate\")\\\n",
    "    .withColumnRenamed(\"Job ID\",\"jobId\")\\\n",
    "    .withColumnRenamed(\"Salary Frequency\",\"salaryFrequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|         jobCategory|  c|\n",
      "+--------------------+---+\n",
      "|Engineering, Arch...|504|\n",
      "|Technology, Data ...|313|\n",
      "|       Legal Affairs|226|\n",
      "|Public Safety, In...|182|\n",
      "|Building Operatio...|181|\n",
      "|Finance, Accounti...|169|\n",
      "|Administration & ...|134|\n",
      "|Constituent Servi...|129|\n",
      "|              Health|125|\n",
      "|Policy, Research ...|124|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.groupBy(\"jobCategory\").agg(count(\"*\").alias(\"c\")).orderBy(col(\"c\").desc()).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whats the salary distribution per job category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|salaryFrequency|\n",
      "+---------------+\n",
      "|         Annual|\n",
      "|          Daily|\n",
      "|         Hourly|\n",
      "+---------------+\n",
      "\n",
      "+--------------------+------------------+----------------+----------------+\n",
      "|         jobCategory| AverageSalaryMean|AverageSalaryMin|AverageSalaryMax|\n",
      "+--------------------+------------------+----------------+----------------+\n",
      "|Administration & ...|          218587.0|        218587.0|        218587.0|\n",
      "|Engineering, Arch...|          198518.0|        198518.0|        198518.0|\n",
      "|Engineering, Arch...|          196042.5|        182500.0|        209585.0|\n",
      "|Health Policy, Re...|          128694.5|         94889.0|        162500.0|\n",
      "|Engineering, Arch...|          128247.5|        128247.5|        128247.5|\n",
      "|Engineering, Arch...|          128247.5|        128247.5|        128247.5|\n",
      "|Communications & ...|          125000.0|        125000.0|        125000.0|\n",
      "|Administration & ...|          118287.0|        118287.0|        118287.0|\n",
      "|Constituent Servi...|116900.33333333333|         58500.0|        217201.0|\n",
      "|Constituent Servi...|          103680.5|        103680.5|        103680.5|\n",
      "+--------------------+------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.createOrReplaceTempView(\"dfsql\")\n",
    "spark.sql(\"select distinct salaryFrequency from dfsql\").show()\n",
    "\n",
    "# Assuming 8 working hours per day and 250 working days per year\n",
    "hours_per_day = 8\n",
    "days_per_year = 250\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"annual_salary_from\",\n",
    "    when(col(\"salaryFrequency\") == \"hourly\", col(\"salaryRangeFrom\") * hours_per_day * days_per_year)\n",
    "    .when(col(\"salaryFrequency\") == \"daily\", col(\"salaryRangeFrom\") * days_per_year)\n",
    "    .otherwise(col(\"salaryRangeFrom\")),\n",
    ").withColumn(\n",
    "    \"annual_salary_to\",\n",
    "    when(col(\"salaryFrequency\") == \"hourly\", col(\"salaryRangeTo\") * hours_per_day * days_per_year)\n",
    "    .when(col(\"salaryFrequency\") == \"daily\", col(\"salaryRangeTo\") * days_per_year)\n",
    "    .otherwise(col(\"salaryRangeTo\")),\n",
    ")\n",
    "\n",
    "\n",
    "df = df.withColumn(\"AverageSalary\",((col(\"annual_salary_from\")+col(\"annual_salary_to\"))/2))\n",
    "\n",
    "df.groupBy(\"jobCategory\").agg(mean(\"AverageSalary\").alias(\"AverageSalaryMean\"),\\\n",
    "                              min(\"AverageSalary\").alias(\"AverageSalaryMin\"),\\\n",
    "                              max(\"AverageSalary\").alias(\"AverageSalaryMax\"),\\\n",
    "                             ).orderBy(col(\"AverageSalaryMean\").desc()).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there any correlation between the higher degree and the salary?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Level|\n",
      "+-----+\n",
      "|   M7|\n",
      "|   M6|\n",
      "|   M5|\n",
      "|   M4|\n",
      "|   M3|\n",
      "|   M2|\n",
      "|   M1|\n",
      "|   4B|\n",
      "|   4A|\n",
      "|    4|\n",
      "|    3|\n",
      "|    2|\n",
      "|    1|\n",
      "|    0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Level\").distinct().orderBy(col(\"Level\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|standardizedLevel|\n",
      "+-------+-----------------+\n",
      "|  count|             2946|\n",
      "|   mean|2.205702647657841|\n",
      "| stddev|2.932479796587177|\n",
      "|    min|                0|\n",
      "|    max|               13|\n",
      "+-------+-----------------+\n",
      "\n",
      "Correlation between Level and Average Salary: 0.581309376958865\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# assume 0 to 4 are static, 4A must be 5,4B must be 6, M1 is 7 and so on.. \n",
    "# allowing all values in level to be numerical and in order\n",
    "def standardize_levels(level):\n",
    "    \n",
    "    level = level.strip()\n",
    "    \n",
    "    if level is None:\n",
    "        return None\n",
    "    \n",
    "    elif level.startswith(\"M\"):\n",
    "        return int(level[1:]) + 6\n",
    "    \n",
    "    elif level == \"4A\":\n",
    "        return 5\n",
    "    elif level == \"4B\":\n",
    "        return 6\n",
    "    else:\n",
    "        return int(level)\n",
    "    \n",
    "standardize_levels_udf = udf(standardize_levels, IntegerType())\n",
    "\n",
    "df = df.withColumn(\"standardizedLevel\",standardize_levels_udf(col(\"level\")))\n",
    "\n",
    "df.describe(\"standardizedLevel\").show()\n",
    "\n",
    "correlation = df.stat.corr(\"standardizedLevel\", \"AverageSalary\")\n",
    "print(\"Correlation between Level and Average Salary:\", correlation)\n",
    "\n",
    "## There is a positive correlation between the degree and the salary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whats the job posting having the highest salary per agency?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+------------------------------------------------------------+-------------+\n",
      "|Agency                        |jobId |businessTitle                                               |AverageSalary|\n",
      "+------------------------------+------+------------------------------------------------------------+-------------+\n",
      "|LANDMARKS PRESERVATION COMM   |425347|LANDMARKS PRESERVATIONIST, PRESERVATION DEPT                |60103.5      |\n",
      "|OFFICE OF COLLECTIVE BARGAININ|170989|COLLEGE AIDE - CLERICAL                                     |9.555        |\n",
      "|FIRE DEPARTMENT               |420216|Senior Enterprise Applications Integration Developer        |120474.5     |\n",
      "|ADMIN FOR CHILDREN'S SVCS     |407253|Assistant Commissioner                                      |117474.5     |\n",
      "|MANHATTAN COMMUNITY BOARD #8  |369120|Community Assistant                                         |19.0         |\n",
      "|TAX COMMISSION                |423630|CITY ASSESSOR                                               |45088.5      |\n",
      "|HRA/DEPT OF SOCIAL SERVICES   |424997|EXECUTIVE DIRECTOR, SERVER INFRASTRUCTURE - BUILD           |112527.5     |\n",
      "|TAXI & LIMOUSINE COMMISSION   |413804|Executive Director, Technology Strategy                     |140000.0     |\n",
      "|EQUAL EMPLOY PRACTICES COMM   |420065|Director of Learning and Development                        |67970.0      |\n",
      "|DEPARTMENT OF BUSINESS SERV.  |97899 |EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT                    |111377.0     |\n",
      "|DEPT OF DESIGN & CONSTRUCTION |416442|Associate Commissioner                                      |151795.0     |\n",
      "|TEACHERS RETIREMENT SYSTEM    |420740|AGENCY ATTORNEY INTERNE                                     |69078.5      |\n",
      "|DEPARTMENT OF CORRECTION      |423322|Assistant Commissioner, Internal Communications             |137500.0     |\n",
      "|FINANCIAL INFO SVCS AGENCY    |424356|Windows Technical Project Manager                           |135000.0     |\n",
      "|OFFICE OF EMERGENCY MANAGEMENT|417137|DISABILITY ACCESS AND FUNCTIONAL NEEDS MANAGER              |70995.0      |\n",
      "|HOUSING PRESERVATION & DVLPMNT|423210|Assistant Commissioner of Community Partnerships and Finance|135000.0     |\n",
      "|CIVILIAN COMPLAINT REVIEW BD  |421027|Policy and Legal                                            |115732.0     |\n",
      "|OFFICE OF MANAGEMENT & BUDGET |423972|Deputy Assistant Director  SOCIAL SERVICES                  |117810.0     |\n",
      "|MAYORS OFFICE OF CONTRACT SVCS|417288|ETL Developer, Enterprise Data Services                     |110000.0     |\n",
      "|DEPT OF CITYWIDE ADMIN SVCS   |417281|Director, Deep Energy Retrofit Program                      |117500.0     |\n",
      "+------------------------------+------+------------------------------------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"dfsql\")\n",
    "spark.sql(\"select Agency,jobId,businessTitle,AverageSalary from (\\\n",
    "select Agency,jobId,AverageSalary,businessTitle,row_number() over(partition by Agency order by AverageSalary desc) rnum\\\n",
    "    from dfsql) q where rnum=1\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whats the job positings average salary per agency for the last 2 years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------+\n",
      "|Agency                        |avg(averageSalary)|\n",
      "+------------------------------+------------------+\n",
      "|FIRE DEPARTMENT               |54674.89          |\n",
      "|ADMIN FOR CHILDREN'S SVCS     |64325.4375        |\n",
      "|MANHATTAN COMMUNITY BOARD #8  |19.0              |\n",
      "|TAX COMMISSION                |20456.35          |\n",
      "|HRA/DEPT OF SOCIAL SERVICES   |60794.0           |\n",
      "|TAXI & LIMOUSINE COMMISSION   |48438.17118333334 |\n",
      "|DEPARTMENT OF BUSINESS SERV.  |62379.103955555554|\n",
      "|DEPT OF DESIGN & CONSTRUCTION |77807.171875      |\n",
      "|TEACHERS RETIREMENT SYSTEM    |69078.5           |\n",
      "|FINANCIAL INFO SVCS AGENCY    |93994.5           |\n",
      "|DEPARTMENT OF CORRECTION      |62190.938710526316|\n",
      "|HOUSING PRESERVATION & DVLPMNT|84882.17857142857 |\n",
      "|CIVILIAN COMPLAINT REVIEW BD  |54142.566666666666|\n",
      "|OFFICE OF MANAGEMENT & BUDGET |70760.09999999999 |\n",
      "|MAYORS OFFICE OF CONTRACT SVCS|87357.14285714286 |\n",
      "|DEPT OF CITYWIDE ADMIN SVCS   |34120.973333333335|\n",
      "|DEPARTMENT OF CITY PLANNING   |48758.75          |\n",
      "|ADMIN TRIALS AND HEARINGS     |23680.396212000003|\n",
      "|DEPARTMENT OF SANITATION      |27521.474         |\n",
      "|DEPT. OF HOMELESS SERVICES    |36267.5           |\n",
      "+------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"dfsql\")\n",
    "spark.sql(\"select Agency,avg(averageSalary) from dfsql \\\n",
    "where to_date(substr(postingDate,1,10),'yyyy-MM-dd') > date_sub(current_timestamp(),730)\\\n",
    "group by Agency\").show(truncate=False)\n",
    "\n",
    "## The query works if we increase the date sub days, but there is no recent data in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the highest paid skills in the US market?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Output column tokenss already exists.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o798.transform.\n: java.lang.IllegalArgumentException: Output column tokenss already exists.\n\tat org.apache.spark.ml.UnaryTransformer.transformSchema(Transformer.scala:112)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.UnaryTransformer.transform(Transformer.scala:120)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7ff4a8f71c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_skills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Minimum Qual Requirements\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min_qual_skills\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-7ff4a8f71c3e>\u001b[0m in \u001b[0;36mextract_skills\u001b[0;34m(df, input_col, output_col)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_skills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokenss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mremover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStopWordsRemover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Output column tokenss already exists.'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, mean\n",
    "\n",
    "def extract_skills(df, input_col, output_col):\n",
    "    tokenizer = Tokenizer(inputCol=input_col, outputCol=\"tokenss\")\n",
    "    df = tokenizer.transform(df)\n",
    "    \n",
    "    remover = StopWordsRemover(inputCol=\"tokens\", outputCol=output_col)\n",
    "    df = remover.transform(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = extract_skills(df, \"Minimum Qual Requirements\", \"min_qual_skills\")\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df_skills = df.select(\"min_qual_skills\", \"AverageSalary\").withColumn(\"skill\", explode(col(\"min_qual_skills\")))\n",
    "\n",
    "highest_paid_skills = (\n",
    "    df_skills.groupBy(\"skill\")\n",
    "    .agg(mean(\"AverageSalary\").alias(\"average_salary\"))\n",
    "    .orderBy(col(\"average_salary\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "highest_paid_skills.show(truncate=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
